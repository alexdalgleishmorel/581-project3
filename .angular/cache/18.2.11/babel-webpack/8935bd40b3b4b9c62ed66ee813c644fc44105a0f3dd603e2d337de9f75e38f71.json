{"ast":null,"code":"import _asyncToGenerator from \"/Users/alexdalgleishmorel/Desktop/UofC/FALL 24/581/581-project3/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport * as faceapi from 'face-api.js';\nimport * as i0 from \"@angular/core\";\nconst _c0 = [\"video\"];\nconst _c1 = [\"overlay\"];\nexport class MirrorComponent {\n  ngOnInit() {\n    var _this = this;\n    return _asyncToGenerator(function* () {\n      yield _this.loadModels();\n      _this.startVideo();\n    })();\n  }\n  loadModels() {\n    return _asyncToGenerator(function* () {\n      // Load face detection models\n      const modelPath = '/assets/models';\n      yield faceapi.nets.tinyFaceDetector.loadFromUri(modelPath);\n      yield faceapi.nets.faceLandmark68Net.loadFromUri(modelPath);\n      yield faceapi.nets.faceRecognitionNet.loadFromUri(modelPath);\n    })();\n  }\n  startVideo() {\n    var _this2 = this;\n    return _asyncToGenerator(function* () {\n      try {\n        const stream = yield navigator.mediaDevices.getUserMedia({\n          video: true\n        });\n        _this2.video.nativeElement.srcObject = stream;\n        _this2.video.nativeElement.onloadedmetadata = () => {\n          // Start detecting faces once the video has metadata loaded\n          _this2.detectFaces();\n        };\n      } catch (error) {\n        console.error('Error accessing webcam:', error);\n      }\n    })();\n  }\n  detectFaces() {\n    var _this3 = this;\n    const canvas = this.overlay.nativeElement;\n    // Get the actual video dimensions after metadata is loaded\n    const videoWidth = this.video.nativeElement.videoWidth;\n    const videoHeight = this.video.nativeElement.videoHeight;\n    // Set canvas dimensions to match the video dimensions\n    canvas.width = videoWidth;\n    canvas.height = videoHeight;\n    const displaySize = {\n      width: videoWidth,\n      height: videoHeight\n    };\n    faceapi.matchDimensions(canvas, displaySize);\n    setInterval( /*#__PURE__*/_asyncToGenerator(function* () {\n      const detections = yield faceapi.detectAllFaces(_this3.video.nativeElement, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();\n      // Resize detections to match video display size\n      const resizedDetections = faceapi.resizeResults(detections, displaySize);\n      // Clear the overlay and draw new detections\n      canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);\n      faceapi.draw.drawDetections(canvas, resizedDetections);\n      faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);\n    }), 100);\n  }\n  static {\n    this.ɵfac = function MirrorComponent_Factory(__ngFactoryType__) {\n      return new (__ngFactoryType__ || MirrorComponent)();\n    };\n  }\n  static {\n    this.ɵcmp = /*@__PURE__*/i0.ɵɵdefineComponent({\n      type: MirrorComponent,\n      selectors: [[\"mirror\"]],\n      viewQuery: function MirrorComponent_Query(rf, ctx) {\n        if (rf & 1) {\n          i0.ɵɵviewQuery(_c0, 7);\n          i0.ɵɵviewQuery(_c1, 7);\n        }\n        if (rf & 2) {\n          let _t;\n          i0.ɵɵqueryRefresh(_t = i0.ɵɵloadQuery()) && (ctx.video = _t.first);\n          i0.ɵɵqueryRefresh(_t = i0.ɵɵloadQuery()) && (ctx.overlay = _t.first);\n        }\n      },\n      decls: 9,\n      vars: 0,\n      consts: [[\"video\", \"\"], [\"overlay\", \"\"], [1, \"content-title\"], [1, \"outer-content\"], [1, \"mirror-border\"], [1, \"inner-content\"], [\"autoplay\", \"\", \"muted\", \"\"]],\n      template: function MirrorComponent_Template(rf, ctx) {\n        if (rf & 1) {\n          i0.ɵɵelementStart(0, \"div\", 2);\n          i0.ɵɵtext(1, \"Mirror View\");\n          i0.ɵɵelementEnd();\n          i0.ɵɵelementStart(2, \"div\", 3)(3, \"div\", 4)(4, \"div\", 5);\n          i0.ɵɵelement(5, \"video\", 6, 0)(7, \"canvas\", null, 1);\n          i0.ɵɵelementEnd()()();\n        }\n      },\n      styles: [\".content-title[_ngcontent-%COMP%] {\\n  font-size: 1.5rem;\\n  text-align: center;\\n  color: #333;\\n  margin-bottom: 20px;\\n}\\n\\n.outer-content[_ngcontent-%COMP%] {\\n  width: 100%;\\n  height: 90%;\\n  background-color: whitesmoke;\\n  border-radius: 10px;\\n  padding: 10px;\\n  display: flex;\\n  justify-content: center;\\n  align-items: center;\\n}\\n\\n.mirror-border[_ngcontent-%COMP%] {\\n  width: 100%;\\n  height: 100%;\\n  padding: 25px;\\n  display: flex;\\n  justify-content: center;\\n  align-items: center;\\n  border-radius: 10px;\\n  background-image: url(\\\"/assets/wood-texture.jpg\\\");\\n  background-size: cover;\\n  background-position: center;\\n}\\n\\n.inner-content[_ngcontent-%COMP%] {\\n  position: relative;\\n  width: 100%;\\n  height: 100%;\\n  background-color: whitesmoke;\\n  border-radius: 10px;\\n  padding: 10px;\\n  overflow: hidden;\\n}\\n.inner-content[_ngcontent-%COMP%]   video[_ngcontent-%COMP%], .inner-content[_ngcontent-%COMP%]   canvas[_ngcontent-%COMP%] {\\n  position: absolute;\\n  top: 0;\\n  left: 0;\\n  width: 100%;\\n  height: 100%;\\n}\\n/*# sourceMappingURL=data:application/json;charset=utf-8;base64,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 */\"]\n    });\n  }\n}","map":{"version":3,"names":["faceapi","MirrorComponent","ngOnInit","_this","_asyncToGenerator","loadModels","startVideo","modelPath","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","_this2","stream","navigator","mediaDevices","getUserMedia","video","nativeElement","srcObject","onloadedmetadata","detectFaces","error","console","_this3","canvas","overlay","videoWidth","videoHeight","width","height","displaySize","matchDimensions","setInterval","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","resizedDetections","resizeResults","getContext","clearRect","draw","drawDetections","drawFaceLandmarks","selectors","viewQuery","MirrorComponent_Query","rf","ctx","i0","ɵɵelementStart","ɵɵtext","ɵɵelementEnd","ɵɵelement"],"sources":["/Users/alexdalgleishmorel/Desktop/UofC/FALL 24/581/581-project3/src/app/components/mirror/mirror.component.ts","/Users/alexdalgleishmorel/Desktop/UofC/FALL 24/581/581-project3/src/app/components/mirror/mirror.component.html"],"sourcesContent":["import { Component, ElementRef, OnInit, ViewChild } from '@angular/core';\nimport * as faceapi from 'face-api.js';\n\n@Component({\n  selector: 'mirror',\n  templateUrl: './mirror.component.html',\n  styleUrls: ['./mirror.component.scss'],\n})\nexport class MirrorComponent implements OnInit {\n  @ViewChild('video', { static: true }) video!: ElementRef;\n  @ViewChild('overlay', { static: true }) overlay!: ElementRef;\n\n  async ngOnInit() {\n    await this.loadModels();\n    this.startVideo();\n  }\n\n  async loadModels() {\n    // Load face detection models\n    const modelPath = '/assets/models';\n    await faceapi.nets.tinyFaceDetector.loadFromUri(modelPath);\n    await faceapi.nets.faceLandmark68Net.loadFromUri(modelPath);\n    await faceapi.nets.faceRecognitionNet.loadFromUri(modelPath);\n  }\n\n  async startVideo() {\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n      this.video.nativeElement.srcObject = stream;\n  \n      this.video.nativeElement.onloadedmetadata = () => {\n        // Start detecting faces once the video has metadata loaded\n        this.detectFaces();\n      };\n    } catch (error) {\n      console.error('Error accessing webcam:', error);\n    }\n  }\n\n  detectFaces() {\n    const canvas = this.overlay.nativeElement;\n  \n    // Get the actual video dimensions after metadata is loaded\n    const videoWidth = this.video.nativeElement.videoWidth;\n    const videoHeight = this.video.nativeElement.videoHeight;\n  \n    // Set canvas dimensions to match the video dimensions\n    canvas.width = videoWidth;\n    canvas.height = videoHeight;\n  \n    const displaySize = { width: videoWidth, height: videoHeight };\n    faceapi.matchDimensions(canvas, displaySize);\n  \n    setInterval(async () => {\n      const detections = await faceapi\n        .detectAllFaces(this.video.nativeElement, new faceapi.TinyFaceDetectorOptions())\n        .withFaceLandmarks();\n  \n      // Resize detections to match video display size\n      const resizedDetections = faceapi.resizeResults(detections, displaySize);\n  \n      // Clear the overlay and draw new detections\n      canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);\n      faceapi.draw.drawDetections(canvas, resizedDetections);\n      faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);\n    }, 100);\n  }\n}\n","<div class=\"content-title\">Mirror View</div>\n<div class=\"outer-content\">\n  <div class=\"mirror-border\">\n    <div class=\"inner-content\">\n      <video #video autoplay muted></video>\n      <canvas #overlay></canvas>\n    </div>\n  </div>\n</div>\n"],"mappings":";AACA,OAAO,KAAKA,OAAO,MAAM,aAAa;;;;AAOtC,OAAM,MAAOC,eAAe;EAIpBC,QAAQA,CAAA;IAAA,IAAAC,KAAA;IAAA,OAAAC,iBAAA;MACZ,MAAMD,KAAI,CAACE,UAAU,EAAE;MACvBF,KAAI,CAACG,UAAU,EAAE;IAAC;EACpB;EAEMD,UAAUA,CAAA;IAAA,OAAAD,iBAAA;MACd;MACA,MAAMG,SAAS,GAAG,gBAAgB;MAClC,MAAMP,OAAO,CAACQ,IAAI,CAACC,gBAAgB,CAACC,WAAW,CAACH,SAAS,CAAC;MAC1D,MAAMP,OAAO,CAACQ,IAAI,CAACG,iBAAiB,CAACD,WAAW,CAACH,SAAS,CAAC;MAC3D,MAAMP,OAAO,CAACQ,IAAI,CAACI,kBAAkB,CAACF,WAAW,CAACH,SAAS,CAAC;IAAC;EAC/D;EAEMD,UAAUA,CAAA;IAAA,IAAAO,MAAA;IAAA,OAAAT,iBAAA;MACd,IAAI;QACF,MAAMU,MAAM,SAASC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;UAAEC,KAAK,EAAE;QAAI,CAAE,CAAC;QACzEL,MAAI,CAACK,KAAK,CAACC,aAAa,CAACC,SAAS,GAAGN,MAAM;QAE3CD,MAAI,CAACK,KAAK,CAACC,aAAa,CAACE,gBAAgB,GAAG,MAAK;UAC/C;UACAR,MAAI,CAACS,WAAW,EAAE;QACpB,CAAC;MACH,CAAC,CAAC,OAAOC,KAAK,EAAE;QACdC,OAAO,CAACD,KAAK,CAAC,yBAAyB,EAAEA,KAAK,CAAC;MACjD;IAAC;EACH;EAEAD,WAAWA,CAAA;IAAA,IAAAG,MAAA;IACT,MAAMC,MAAM,GAAG,IAAI,CAACC,OAAO,CAACR,aAAa;IAEzC;IACA,MAAMS,UAAU,GAAG,IAAI,CAACV,KAAK,CAACC,aAAa,CAACS,UAAU;IACtD,MAAMC,WAAW,GAAG,IAAI,CAACX,KAAK,CAACC,aAAa,CAACU,WAAW;IAExD;IACAH,MAAM,CAACI,KAAK,GAAGF,UAAU;IACzBF,MAAM,CAACK,MAAM,GAAGF,WAAW;IAE3B,MAAMG,WAAW,GAAG;MAAEF,KAAK,EAAEF,UAAU;MAAEG,MAAM,EAAEF;IAAW,CAAE;IAC9D7B,OAAO,CAACiC,eAAe,CAACP,MAAM,EAAEM,WAAW,CAAC;IAE5CE,WAAW,eAAA9B,iBAAA,CAAC,aAAW;MACrB,MAAM+B,UAAU,SAASnC,OAAO,CAC7BoC,cAAc,CAACX,MAAI,CAACP,KAAK,CAACC,aAAa,EAAE,IAAInB,OAAO,CAACqC,uBAAuB,EAAE,CAAC,CAC/EC,iBAAiB,EAAE;MAEtB;MACA,MAAMC,iBAAiB,GAAGvC,OAAO,CAACwC,aAAa,CAACL,UAAU,EAAEH,WAAW,CAAC;MAExE;MACAN,MAAM,CAACe,UAAU,CAAC,IAAI,CAAC,CAACC,SAAS,CAAC,CAAC,EAAE,CAAC,EAAEhB,MAAM,CAACI,KAAK,EAAEJ,MAAM,CAACK,MAAM,CAAC;MACpE/B,OAAO,CAAC2C,IAAI,CAACC,cAAc,CAAClB,MAAM,EAAEa,iBAAiB,CAAC;MACtDvC,OAAO,CAAC2C,IAAI,CAACE,iBAAiB,CAACnB,MAAM,EAAEa,iBAAiB,CAAC;IAC3D,CAAC,GAAE,GAAG,CAAC;EACT;;;uCA1DWtC,eAAe;IAAA;EAAA;;;YAAfA,eAAe;MAAA6C,SAAA;MAAAC,SAAA,WAAAC,sBAAAC,EAAA,EAAAC,GAAA;QAAA,IAAAD,EAAA;;;;;;;;;;;;;;;UCR5BE,EAAA,CAAAC,cAAA,aAA2B;UAAAD,EAAA,CAAAE,MAAA,kBAAW;UAAAF,EAAA,CAAAG,YAAA,EAAM;UAGxCH,EAFJ,CAAAC,cAAA,aAA2B,aACE,aACE;UAEzBD,EADA,CAAAI,SAAA,kBAAqC,sBACX;UAGhCJ,EAFI,CAAAG,YAAA,EAAM,EACF,EACF","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}